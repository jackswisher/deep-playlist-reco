{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import time\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import random\n",
    "import scipy as sp\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from functools import partial\n",
    "from multiprocessing.pool import Pool\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in CSVs | Add FID | Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_zero = pd.read_csv(\"Songs/songs0.csv\")\n",
    "file_zero[\"fid\"] = 0\n",
    "file_one = pd.read_csv(\"Songs/songs1.csv\")\n",
    "file_one[\"fid\"] = 1\n",
    "complete_playlists = pd.DataFrame(np.concatenate([file_zero, file_one]), columns = file_zero.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set index to [\"fid\", \"pid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_playlists.set_index([\"fid\", \"pid\"], inplace=True)\n",
    "complete_playlists.sort_index(inplace = True) # Sort index to make indexing faster later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get all unique songs, artists, and albums for Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_unique_songs = complete_playlists['track_name'].unique()\n",
    "all_unique_albums = complete_playlists['album_name'].unique()\n",
    "all_unique_artists = complete_playlists['artist_name'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make unique playlist ID's and split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_playlist_ids = np.unique(complete_playlists.index.values)\n",
    "np.random.shuffle(unique_playlist_ids)\n",
    "\n",
    "# 0.8 Test and 0.2 Train Split\n",
    "train_idx_cutoff = int(0.8 * unique_playlist_ids.shape[0])\n",
    "train_playlist_ids = unique_playlist_ids[0:train_idx_cutoff]\n",
    "test_playlist_ids = unique_playlist_ids[train_idx_cutoff:unique_playlist_ids.shape[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Sparse Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sparse matrix based on passed in filter methods\n",
    "def createSparseMatrix(train_playlist_ids, all_candidates_filter, filter_method = \"track_name\"):    \n",
    "    rows_list = []\n",
    "    for ids in train_playlist_ids:\n",
    "        playlist_filter = complete_playlists.loc[ids][filter_method]\n",
    "        ones_idx = np.where(np.isin(all_candidates_filter, playlist_filter))[0]\n",
    "        row = np.zeros(all_candidates_filter.shape)\n",
    "        row[ones_idx] = 1 / playlist_filter.shape[0]\n",
    "        rows_list.append(row)\n",
    "    train_sparse = sp.sparse.csr_matrix(np.vstack(rows_list))\n",
    "    return train_sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kNN with Collaborative Filtering on Songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "song_sm = createSparseMatrix(train_playlist_ids, all_unique_songs, \"track_name\")\n",
    "model_knn_songs = NearestNeighbors(metric='cosine', \n",
    "                                        algorithm='brute', \n",
    "                                        n_neighbors=20, n_jobs=-1).fit(song_sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kNN with Collaborative Filtering on Artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_sm = createSparseMatrix(train_playlist_ids, all_unique_artists, \"artist_name\")\n",
    "model_knn_artists = NearestNeighbors(metric='cosine', \n",
    "                                        algorithm='brute', \n",
    "                                        n_neighbors=20, n_jobs=-1).fit(artist_sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kNN with Collaborative Filtering on Albums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "album_sm = createSparseMatrix(train_playlist_ids, all_unique_albums, \"album_name\")\n",
    "model_knn_albums = NearestNeighbors(metric='cosine', \n",
    "                                        algorithm='brute', \n",
    "                                        n_neighbors=20, n_jobs=-1).fit(album_sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Sparse Vector for Test Playlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSparseVector(test_playlist, all_candidates_filter, filter_method = \"track_name\"):\n",
    "    # Takes a playlist and creates a sparse vector\n",
    "    test_playlist_filter = test_playlist[filter_method]\n",
    "    ones_idx = np.where(np.isin(all_candidates_filter, test_playlist_filter))\n",
    "    row = np.zeros(all_candidates_filter.shape)\n",
    "    row[ones_idx] = 1\n",
    "    return row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Test Set into Train and Validation\n",
    "\n",
    "test_playlist_ids: These are the ids for the playlists that we want to make predictions on\n",
    "- We split each test playlist into a \"train\" and \"validation\" set. \n",
    "- We create sparse matrices from the train part, to create a similarity value for the test playlist to existing playlists in our database. 3 are created for our 3 collaborative filtering techniques\n",
    "- Then, we use the similarity value to choose playlists that are most similar and recommend the songs from that playlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(109)\n",
    "# Sparse matrices for the three collaborative filtering techniques\n",
    "song_sm_list = []\n",
    "album_sm_list = []\n",
    "artist_sm_list = []\n",
    "# Creating a list of validation songs that we later test against\n",
    "val_list = []\n",
    "\n",
    "# For each playlist in test playlists\n",
    "for ids in test_playlist_ids:\n",
    "    test_playlist = complete_playlists.loc[ids]\n",
    "    \n",
    "    # Split into test songs and validation songs\n",
    "    idx = np.random.choice(np.arange(len(test_playlist)), int(0.8 * len(test_playlist)), replace=False)\n",
    "    test_idx = np.where(np.isin(np.arange(len(test_playlist)), idx, invert=True))[0]\n",
    "    predictor_playlist = test_playlist.iloc[idx]\n",
    "    evaluation_playlist = test_playlist.iloc[test_idx]\n",
    "    val_list.append(evaluation_playlist)\n",
    "    \n",
    "    # Make the sparse vector for each test playlist - cf on songs\n",
    "    sparse_song_row = createSparseVector(predictor_playlist, all_unique_songs, \"track_name\")\n",
    "    song_sm_list.append(sparse_song_row)\n",
    "    \n",
    "    # Make the sparse vector for each test playlist - cf on album\n",
    "    sparse_album_row = createSparseVector(predictor_playlist, all_unique_albums, \"album_name\")\n",
    "    album_sm_list.append(sparse_album_row)\n",
    "    \n",
    "    # Make the sparse vector for each test playlist - cf on artist\n",
    "    sparse_artist_row = createSparseVector(predictor_playlist, all_unique_artists, \"artist_name\")\n",
    "    artist_sm_list.append(sparse_artist_row)\n",
    "\n",
    "# Compile all vectors for test playlists into a sparse matrix\n",
    "song_sm = sp.sparse.csr_matrix(np.vstack(song_sm_list))\n",
    "album_sm = sp.sparse.csr_matrix(np.vstack(album_sm_list))\n",
    "artist_sm = sp.sparse.csr_matrix(np.vstack(artist_sm_list))\n",
    "\n",
    "# Store the validation sets of each playlist\n",
    "val_df = pd.concat(val_list)\n",
    "test_indices = test_playlist_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSongPredictions(X, model, train_indices, candidate_playlists, top_n, test_indices):\n",
    "    distances, neighbors = model.kneighbors(X)\n",
    "    predictions_list = []\n",
    "    # For each playlist in the sparse matrix passed in\n",
    "    for i in range(test_indices.shape[0]):\n",
    "        best_candidates = neighbors[i][distances[i] != 1]\n",
    "        best_distances = distances[i][distances[i] != 1]\n",
    "        if best_candidates.size != 0:\n",
    "            # get the IDs in candidate_playlists [our database of playlists] with the lowest distance\n",
    "            candidate_idx = train_indices[best_candidates]\n",
    "        else:\n",
    "            # TODO: Change\n",
    "            predictions_list.append(pd.DataFrame(columns = candidate_playlists.columns))\n",
    "            continue\n",
    "            \n",
    "        candidates_df = candidate_playlists.loc[candidate_idx]\n",
    "        \n",
    "        # transform the best_distances into a form that can be concatenated\n",
    "        lengths = candidates_df.groupby(level=[0,1])[\"pos\"].count().values\n",
    "        candidates_df[\"distance\"] = np.repeat(best_distances, lengths)\n",
    "        \n",
    "        # want only the songs that are not in the test playlist\n",
    "        idx_songs_in_playlist = np.where(np.isin(candidates_df[\"track_name\"].values,\n",
    "                                                 complete_playlists.loc[test_indices[i]][\"track_name\"].values))[0]\n",
    "        not_in_train_df = candidates_df.iloc[idx_songs_in_playlist]\n",
    "        \n",
    "        # drop duplicates from final recommendation list\n",
    "        no_duplicates_df = not_in_train_df.drop_duplicates(\"track_name\")\n",
    "        if no_duplicates_df.shape[0] < top_n:\n",
    "            predictions_list.append(no_duplicates_df)\n",
    "        else:\n",
    "            predictions_list.append(no_duplicates_df.iloc[0:top_n])\n",
    "    return predictions_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction with CF on Songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_cf_song = getSongPredictions(song_sm, model_knn_songs, \n",
    "                                         train_playlist_ids, complete_playlists, \n",
    "                                         500, test_playlist_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction with CF on Artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_cf_artist = getSongPredictions(artist_sm, model_knn_artists, \n",
    "                                           train_playlist_ids, complete_playlists, \n",
    "                                           500, test_playlist_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction with CF on Album"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_cf_album = getSongPredictions(album_sm, model_knn_albums, \n",
    "                                          train_playlist_ids, complete_playlists, \n",
    "                                          500, test_playlist_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate CF on Songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clickEvaluation(validation_playlist_df, predictions_df, test_indices):\n",
    "    clicks = []\n",
    "    validation_playlist_df.sort_index(inplace = True)\n",
    "    for i in range(test_indices.shape[0]):\n",
    "        predictions = predictions_df[i]\n",
    "        idx = test_indices[i]\n",
    "        val_playlist = validation_playlist_df.loc[idx]\n",
    "        positions_matching = np.where(np.isin(predictions[\"track_name\"].values, val_playlist['track_name']))[0]\n",
    "        # CLICKS: min pos / 10\n",
    "        if positions_matching.size == 0:\n",
    "            clicks.append(50)\n",
    "        else:\n",
    "            clicks.append(math.ceil(positions_matching[0] / 10))\n",
    "    return np.mean(clicks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.9225"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clickEvaluation(val_df, predictions_cf_song, test_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate CF on Artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.1725"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clickEvaluation(val_df, predictions_cf_artist, test_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate CF on Albums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.955"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clickEvaluation(val_df, predictions_cf_album, test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
