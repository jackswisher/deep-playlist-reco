{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import time\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import random\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outline:\n",
    "* Want to create a training/test set to try CF on\n",
    "* Create SciPy sparse matrix from unique songs\n",
    "    - Rows: Playlists\n",
    "    - Columns: Songs in a given playlist\n",
    "* Filter + predict songs that are in the other playlists that have lowest distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "POSSIBLE CHANGE: If a song appears multiple times in a single playlist, use number of occurrences rather than just presence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_songs = pd.read_csv(\"total_songs_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_playlists = pd.read_csv(\"playlist_data.csv\") # takes 5ish minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get train/test playlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_playlist_ids = np.unique(np.array(complete_playlists[[\"fid\", \"pid\"]]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(unique_playlist_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx_cutoff = int(0.1 * unique_playlist_ids.shape[0])\n",
    "train_playlist_ids = unique_playlist_ids[0:train_idx_cutoff]\n",
    "test_playlist_ids = unique_playlist_ids[train_idx_cutoff:unique_playlist_ids.shape[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create SciPy Spare Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = total_songs['track_name'].unique()\n",
    "complete_playlists.set_index([\"fid\", \"pid\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Careful not to re-run this when not needed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = complete_playlists['track_name'].groupby(level=[0,1])\n",
    "split_into_playlists = [gb.get_group(x) for x in gb.groups]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rows_list = []\n",
    "num_processed = 0\n",
    "for fid, pid in zip(train_playlist_ids[:,0], train_playlist_ids[:,1]):\n",
    "    playlist_songs = split_into_playlists[1000 * fid + pid]\n",
    "    ones_idx = np.where(np.in1d(col_names, playlist_songs))[0]\n",
    "    row = np.zeros(col_names.shape)\n",
    "    row[ones_idx] = 1 / playlist_songs.shape[0]\n",
    "    rows_list.append(row)\n",
    "    num_processed += 1\n",
    "train_sparse = sp.sparse.csr_matrix(np.vstack(rows_list))\n",
    "train_indices = train_playlist_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE TO A FILE, TAKES HELLA LONG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use kNN with cosine distance to find nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_knn = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=20, n_jobs=-1).fit(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actually make predictions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_list = []\n",
    "val_list = []\n",
    "for fid, pid in zip(test_playlist_ids[\"fid\"], test_playlist_ids[\"pid\"]):\n",
    "    playlist_songs = complete_playlists.loc[(fid, pid)]\n",
    "    idx = np.random.choice(np.arange(len(playlist_songs)), int(0.8 * len(playlist_songs)), replace=False)\n",
    "    test_idx = np.where(np.in1d(np.arange(len(playlist_songs)), idx, invert=True))[0]\n",
    "    songs_to_use = playlist_songs[\"track_name\"].values[idx]\n",
    "    songs_to_evaluate = playlist_songs.iloc[test_idx]\n",
    "    val_list.append(songs_to_evaluate)\n",
    "    ones_idx = np.where(np.in1d(col_names, songs_to_use))[0]\n",
    "    row = np.zeros(col_names.shape)\n",
    "    row[ones_idx] = 1 # / songs_to_use.shape[0]\n",
    "    rows_list.append(row)\n",
    "test_df = sp.sparse.csr_matrix(np.vstack(rows_list))\n",
    "val_df = pd.concat(val_list)\n",
    "test_indices = test_playlist_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSongPredictions(X, model, indices, candidate_playlists, top_n, col_names):\n",
    "    distances, neighbors = model.kneighbors(X)\n",
    "    predictions_list = []\n",
    "    for i in range(X.shape[0]):\n",
    "        best_candidates = neighbors[i][distances[i] != 1]\n",
    "        best_distances = distances[i][distances[i] != 1]\n",
    "        if best_candidates.size != 0:\n",
    "            # get the place in candidate_playlists with the lowest distance\n",
    "            candidate_idx = indices[best_candidates]\n",
    "        else:\n",
    "            # TODO: Change\n",
    "            predictions_list.append(pd.DataFrame(columns = candidate_playlists.columns))\n",
    "            continue\n",
    "            \n",
    "        candidates_df = candidate_playlists.loc[list(map(tuple, candidate_idx))]\n",
    "        \n",
    "        # transform the best_distances into a form that can be concatenated\n",
    "        lengths = candidates_df.groupby(level=[0,1])[\"pos\"].count().values\n",
    "        \n",
    "\n",
    "        candidates_df[\"distance\"] = np.repeat(best_distances, lengths)\n",
    "        \n",
    "        # want only the songs that are not in the playlist\n",
    "        not_in_train_df = candidates_df.iloc[np.where(np.in1d(candidates_df[\"track_name\"].values, \n",
    "                                                      col_names[X[i].toarray()[0] != 0], invert=True))[0]]\n",
    "        \n",
    "        # drop duplicates\n",
    "        no_duplicates_df = not_in_train_df.drop_duplicates(\"track_name\")\n",
    "        if no_duplicates_df.shape[0] < top_n:\n",
    "            predictions_list.append(no_duplicates_df)\n",
    "        else:\n",
    "            predictions_list.append(no_duplicates_df.iloc[0:top_n])\n",
    "    return predictions_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predictions_list = getSongPredictions(test_df, model_knn, train_indices, complete_playlists, 500, col_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clicks = []\n",
    "for i in range(test_df.shape[0]):\n",
    "    predictions = predictions_list[i]\n",
    "    idx = test_indices[i]\n",
    "    val_songs = val_df.loc[tuple(idx)]\n",
    "    positions_matching = np.where(np.in1d(predictions[\"track_name\"].values, val_songs['track_name']))[0]\n",
    "    # CLICKS: min pos / 10\n",
    "    if positions_matching.size == 0:\n",
    "        clicks.append(50)\n",
    "    else:\n",
    "        clicks.append(math.ceil(positions_matching[0] / 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances, neighbors = model_knn.kneighbors(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(clicks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "val_songs[\"track_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[\"track_name\"][positions_matching]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
